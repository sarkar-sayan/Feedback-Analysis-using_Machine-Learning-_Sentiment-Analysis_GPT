{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1n0m_gJoX65d8qz1FUmjLO1nNI8xuRjgf",
      "authorship_tag": "ABX9TyP7jS7ig3myjsDQ87gpFnNP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarkar-sayan/Feedback_Analysis-using-Machine_Learning_NLP_GenerativeAI/blob/main/POC_2_Survey_Feedback_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnIsYY2tO0O1",
        "outputId": "670b4fb0-3af1-4cee-fde6-6cf2d5e4387a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GRcpl8vO8lh",
        "outputId": "7cb38b22-4aa1-4958-acca-3a077336ddd0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, FunctionTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "#from langdetect import detect\n",
        "#from googletrans import Translator\n",
        "# Initialize Google Translator\n",
        "#translator = Translator()\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVKpugXlO4ma",
        "outputId": "1b8f67b4-4d59-4236-c0fd-71978e72b00a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "!export GROQ_API_KEY='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'\n",
        "\n",
        "client = Groq(\n",
        "    # This is the default and can be omitted\n",
        "    api_key='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'\n",
        "    #api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")"
      ],
      "metadata": {
        "id": "wl4507SWO_iL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHJYh2eePG-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing function\n",
        "# Translate text if not in English\n",
        "#def translate_text_if_needed(text):\n",
        "#    try:\n",
        "#        language = detect(text)\n",
        "#        if language != 'en':\n",
        "#            translated = translator.translate(text, dest='en')\n",
        "#            return translated.text\n",
        "#        return text\n",
        "#    except Exception as e:\n",
        "#        return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    filtered_text = ' '.join([lemmatizer.lemmatize(word) for word in tokens if word not in stop_words])\n",
        "    return filtered_text\n"
      ],
      "metadata": {
        "id": "V3cH9TbHPPxv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(dataset_url):\n",
        "  df = pd.read_csv(dataset_url)\n",
        "  # preprocess data accroding to survey form\n",
        "  #df.drop('Timestamp = A12 + A4', axis=1, inplace=True)\n",
        "  df = df.dropna(subset=[\"Timestamp = A12 + A4\"])  # if Timestamp == null, that means empty row, i.e, the form has never been filled\n",
        "\n",
        "  # Join all textual columns into one\n",
        "  feedback_columns = [col for col in df.columns if 'Overall feedback' in col]\n",
        "  df['All_feedback'] = df[feedback_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
        "  #df['All_feedback'] = df['All_feedback'].apply(translate_text_if_needed)\n",
        "  df.drop(feedback_columns, axis=1, inplace=True)\n",
        "  # Preprocess textual feedback\n",
        "  df['All_feedback'] = df['All_feedback'].apply(preprocess_text)\n",
        "  return df"
      ],
      "metadata": {
        "id": "DFk9XcgSQNis"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_model(data):\n",
        "  X = data.drop('Final Label', axis=1)\n",
        "  y = data['Final Label']\n",
        "\n",
        "  # Train/Test Split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
        "  # Define ColumnTransformer to separate numerical and text data processing\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "          ('num', StandardScaler(), X.select_dtypes(include='number').columns.tolist()),\n",
        "          ('text', TfidfVectorizer(), 'All_feedback')\n",
        "          ],\n",
        "      remainder='drop'\n",
        "      )\n",
        "\n",
        "  # Define the pipeline\n",
        "  pipeline = Pipeline([\n",
        "      ('preprocessor', preprocessor),\n",
        "      ('classifier', LogisticRegression(random_state=42))\n",
        "      ])\n",
        "\n",
        "  pipeline.fit(X_train, y_train)\n",
        "\n",
        "  # Predict on the test set\n",
        "  y_pred = pipeline.predict(X_test)\n",
        "\n",
        "  #print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "  #print(\"Classification Report:\")\n",
        "  #print(classification_report(y_test, y_pred))\n",
        "  return pipeline"
      ],
      "metadata": {
        "id": "7mtPk4g-SYOk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_feedback_proba(pipeline, sample):\n",
        "    sample_df = pd.DataFrame([sample])\n",
        "    sample_df = sample.to_frame().T\n",
        "    y_prob = pipeline.predict_proba(sample_df)\n",
        "    prob_pos = y_prob[0][1] * 100  # Probability of being positive\n",
        "    prob_neg = y_prob[0][0] * 100  # Probability of being negative\n",
        "    return prob_pos, prob_neg"
      ],
      "metadata": {
        "id": "chgGyXrFPYRW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate detailed feedback using OpenAI's GPT-4\n",
        "def generate_detailed_feedback(numerical_data, textual_feedback, prob_pos, prob_neg):\n",
        "    # Convert numerical_data to a string representation\n",
        "    numerical_data_str = str(numerical_data)\n",
        "\n",
        "    prompt = f\"Using the following numerical ratings and feedback:\\n\\nNumerical Ratings: {numerical_data_str}\\n\\nTextual Feedback: {textual_feedback}\\n\\nProbability of being positive: {prob_pos:.2f}%\\n\\nProbability of being negative: {prob_neg:.2f}%\\n\\nPlease provide a very short final feedback according to the client, i.e, either positive or negative. Not both.Give output in the form of either Positive, Mostly Positive, Negative or Mostly Negative with the probability percentage. And then Improvements or Matters to focus upon:\"\n",
        "    chat_completion = client.chat.completions.create(\n",
        "    messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are an intelligent and helpful assistant.\",\n",
        "    },\n",
        "{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt, # Use the formatted prompt here\n",
        "    },\n",
        "    ],\n",
        "    model=\"llama3-8b-8192\" # Add the model keyword argument here\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content.strip()  # Extract the content from the response\n"
      ],
      "metadata": {
        "id": "22JEbmF3PlFG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feedback(pipeline, sample):\n",
        "  # Example usage\n",
        "  #prob_pos, prob_neg = predict_feedback_proba(pipeline, sample)\n",
        "  #print(f\"Sample:\\n{sample}\")\n",
        "  #print(f\"Probability of being positive: {prob_pos:.2f}%\")\n",
        "  #print(f\"Probability of being negative: {prob_neg:.2f}%\")\n",
        "\n",
        "  numerical_data = sample.drop('All_feedback').to_dict()\n",
        "  textual_feedback = sample['All_feedback']\n",
        "  prob_pos, prob_neg = predict_feedback_proba(pipeline, sample)\n",
        "  detailed_feedback = generate_detailed_feedback(numerical_data, textual_feedback, prob_pos, prob_neg)\n",
        "  return detailed_feedback"
      ],
      "metadata": {
        "id": "FuvUnEaXPqT_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_ready():\n",
        "  dataset_url = input(\"Enter the dataset URL: \")\n",
        "  df = prepare_data(dataset_url)\n",
        "  pipeline = train_test_model(df)\n",
        "  return pipeline"
      ],
      "metadata": {
        "id": "_cn-ZjUsbu2h"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feedback(pipeline):\n",
        "  feedform_url = input(\"Enter the URL where feedback data for generating analysis is stored: \")\n",
        "  data = prepare_data(feedform_url)\n",
        "  df = pd.read_csv(feedform_url)\n",
        "  df['Result'] = \"\"\n",
        "  for i in range(len(data)):\n",
        "    sample = data.iloc[i]\n",
        "    print(\"\\nFeedback: \", i+1)\n",
        "    print(\"Client Name: \", data['Client Name'].iloc[i])\n",
        "    feed = generate_feedback(pipeline, sample)\n",
        "    df.at[i, 'Result'] = feed\n",
        "    print(feed)\n",
        "  #data = data.drop('All_feedback', axis=1)\n",
        "  df.to_csv(feedform_url, index=False)"
      ],
      "metadata": {
        "id": "SnCq-zL8aUKo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_execute():\n",
        "  pipeline = get_model_ready()\n",
        "  get_feedback(pipeline)"
      ],
      "metadata": {
        "id": "yd3cn9BTQDip"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  final_execute()"
      ],
      "metadata": {
        "id": "7XmcwX3Jjyi_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auVE5K3HlVhV",
        "outputId": "701a9218-4427-40ce-dd8d-fa194954b6bd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the dataset URL: /content/drive/MyDrive/Sayan RP files/Datasets/POC_data/Client Feedback Form Training.csv\n",
            "Enter the URL where feedback data for generating analysis is stored: /content/drive/MyDrive/Sayan RP files/Datasets/POC_data/Client Feedback Form Output.csv\n",
            "\n",
            "Feedback:  1\n",
            "Client Name:  A Biswas\n",
            "Based on the given ratings and feedback, here is the final assessment:\n",
            "\n",
            "**Final Assessment:** Mostly Negative (46.81%)\n",
            "\n",
            "**Rationale:** Although the client gave high ratings for the employee's professionalism, courteousness, and knowledge about the business domain, the ratings for communication, promptness, and issue-handling were relatively low. The low scores might have overshadowed the positive aspects, leading to a mostly negative assessment.\n",
            "\n",
            "**Improvements or Matters to Focus Upon:**\n",
            "\n",
            "1. Improve communication skills to ensure clear and effective interaction with clients.\n",
            "2. Enhance responsiveness to client inquiries and concerns to improve promptness and issue resolution.\n",
            "3. Develop deeper understanding of client business requirements to provide more tailored solutions.\n",
            "\n",
            "By addressing these areas, the employee can potentially improve the overall client experience and achieve more positive ratings in the future.\n",
            "\n",
            "Feedback:  2\n",
            "Client Name:  B Chakraborty\n",
            "Final Feedback: Positive\n",
            "\n",
            "Probability of positive feedback: 86.09%\n",
            "\n",
            "Probability of negative feedback: 13.91%\n",
            "\n",
            "Improvements or Matters to focus upon:\n",
            "The client's feedback suggests that the employee had some room for improvement in clarity and understandability of the information provided (2.0/5) and their business domain knowledge (2.0/5). The employee could focus on enhancing these aspects to provide better overall service to clients.\n",
            "\n",
            "Feedback:  3\n",
            "Client Name:  C Das\n",
            "Based on the provided numerical ratings and feedback, I would classify the feedback as:\n",
            "\n",
            "**Mostly Positive** (84.54%)\n",
            "\n",
            "The client was generally satisfied with the employee's communication, prompt response, and clarity of information. However, the client had some concerns about the employee's professionalism and knowledge about technology and the business domain.\n",
            "\n",
            "Feedback:  4\n",
            "Client Name:  D Ezekiel\n",
            "Based on the numerical ratings and feedback, I would output:\n",
            "\n",
            "Feedback: Mostly Negative\n",
            "Probability: 89.04%\n",
            "\n",
            "Improvements or Matters to Focus Upon:\n",
            "\n",
            "* Employees should communicate more effectively and promptly (average ratings of 1.0 and 2.0 respectively).\n",
            "* Employees should improve their understanding of business requirements and technology used (ratings of 1.0 and 1.0 respectively).\n",
            "* Employees should increase their knowledge about the technology used (rating of 1.0).\n",
            "\n",
            "Overall, the client's feedback indicates that the employee's communication, response time, technical knowledge, and understanding of business requirements need improvement.\n",
            "\n",
            "Feedback:  5\n",
            "Client Name:  E Fanta\n",
            "Based on the numerical ratings and textual feedback, I would provide the following final feedback:\n",
            "\n",
            "Feedback: Mostly Negative (66.37%)\n",
            "\n",
            "Improvements or Matters to focus upon:\n",
            "\n",
            "* Employee communication skills could be improved (3.0 out of 10)\n",
            "* Response time could be faster (3.0 out of 10)\n",
            "* Employee could benefit from more experience in the business domain (2.0 out of 10)\n",
            "* Handling issues or concerns could be more effective (2.0 out of 10)\n",
            "* Employee could be more professional, courteous, and respectful during interactions (average rating of 2.0 out of 10)\n",
            "\n",
            "It seems that the employee struggled with understanding the client's business requirements, handling issues, and demonstrating expertise in the business domain. The client also experienced slower response times and felt that the employee could improve their communication and professionalism.\n",
            "\n",
            "Feedback:  6\n",
            "Client Name:  F Giovanna\n",
            "Based on the numerical ratings and feedback, I would provide the following output:\n",
            "\n",
            "Final Feedback: Mostly Positive (67.58%)\n",
            "\n",
            "Improvements/Matters to focus upon:\n",
            "\n",
            "* Communication effectiveness: The client rated the communication effectiveness as 3.0 out of 5, which is below average. The employee could improve their communication skills to better understand the client's needs.\n",
            "* Information clarity: The client rated the clarity and understandability of the information provided as 1.0 out of 5, which is very low. The employee could provide more clear and concise information to the client.\n",
            "* Issue handling: The client rated the employee's ability to handle issues or concerns as 2.0 out of 5, which is below average. The employee could improve their problem-solving skills to better address client concerns.\n",
            "\n",
            "Note: The client's textual feedback suggests that the employee was fast, prompt, and knowledgeable about the technology used, which contributed to the positive feedback. However, there are areas where the employee can improve to provide a more satisfactory experience for the client.\n",
            "\n",
            "Feedback:  7\n",
            "Client Name:  Napoleon Bonaparte\n",
            "Based on the numerical ratings and textual feedback, I would classify the feedback as:\n",
            "\n",
            "**Negative (96.72%)**\n",
            "\n",
            "Improvements or Matters to focus upon:\n",
            "\n",
            "* Improve communication with clients, especially in terms of promptness and clarity.\n",
            "* Enhance employee's understanding of business requirements and technology used.\n",
            "* Increase employee's knowledge about the business domain and industry trends.\n",
            "* Focus on delivering satisfactory solutions to clients.\n",
            "* Work on professionalism, courtesy, and respect during interactions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u6S4oF_HGTod"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}