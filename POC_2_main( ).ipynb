{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOViEfN0DWML3G29P07km7D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarkar-sayan/Feedback_Analysis-using-Machine_Learning_NLP_GenerativeAI/blob/main/POC_2_main(%20).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnIsYY2tO0O1",
        "outputId": "7be036d7-cc7d-47a6-90fe-713d32895047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GRcpl8vO8lh",
        "outputId": "24e3949d-128c-4eca-c1c0-2ea8e3e441fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.0)\n",
            "Installing collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, FunctionTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "#from langdetect import detect\n",
        "#from googletrans import Translator\n",
        "# Initialize Google Translator\n",
        "#translator = Translator()\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVKpugXlO4ma",
        "outputId": "85860ae4-e6e5-4255-ab55-505f5e38b3ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "!export GROQ_API_KEY='YOUR_GROQ_API_KEY'\n",
        "\n",
        "client = Groq(\n",
        "    # This is the default and can be omitted\n",
        "    api_key='YOUR_GROQ_API_KEY'\n",
        "    #api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")"
      ],
      "metadata": {
        "id": "wl4507SWO_iL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHJYh2eePG-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing function\n",
        "# Translate text if not in English\n",
        "#def translate_text_if_needed(text):\n",
        "#    try:\n",
        "#        language = detect(text)\n",
        "#        if language != 'en':\n",
        "#            translated = translator.translate(text, dest='en')\n",
        "#            return translated.text\n",
        "#        return text\n",
        "#    except Exception as e:\n",
        "#        return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    filtered_text = ' '.join([lemmatizer.lemmatize(word) for word in tokens if word not in stop_words])\n",
        "    return filtered_text\n"
      ],
      "metadata": {
        "id": "V3cH9TbHPPxv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(dataset_url):\n",
        "  df = pd.read_csv(dataset_url)\n",
        "  # preprocess data accroding to survey form\n",
        "  df.drop('Timestamp = A12 + A4', axis=1, inplace=True)\n",
        "  df = df.dropna()\n",
        "\n",
        "  # Join all textual columns into one\n",
        "  feedback_columns = [col for col in df.columns if 'Overall feedback' in col]\n",
        "  df['All_feedback'] = df[feedback_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
        "  #df['All_feedback'] = df['All_feedback'].apply(translate_text_if_needed)\n",
        "  df.drop(feedback_columns, axis=1, inplace=True)\n",
        "  df.drop('Final Feedback', axis=1, inplace=True)\n",
        "  # Preprocess textual feedback\n",
        "  df['All_feedback'] = df['All_feedback'].apply(preprocess_text)\n",
        "  return df"
      ],
      "metadata": {
        "id": "DFk9XcgSQNis"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_model(data):\n",
        "  X = data.drop('Final Label', axis=1)\n",
        "  y = data['Final Label']\n",
        "\n",
        "  # Train/Test Split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
        "  # Define ColumnTransformer to separate numerical and text data processing\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "          ('num', StandardScaler(), X.select_dtypes(include='number').columns.tolist()),\n",
        "          ('text', TfidfVectorizer(), 'All_feedback')\n",
        "          ],\n",
        "      remainder='drop'\n",
        "      )\n",
        "\n",
        "  # Define the pipeline\n",
        "  pipeline = Pipeline([\n",
        "      ('preprocessor', preprocessor),\n",
        "      ('classifier', LogisticRegression(random_state=42))\n",
        "      ])\n",
        "\n",
        "  pipeline.fit(X_train, y_train)\n",
        "\n",
        "  # Predict on the test set\n",
        "  y_pred = pipeline.predict(X_test)\n",
        "\n",
        "  #print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "  #print(\"Classification Report:\")\n",
        "  #print(classification_report(y_test, y_pred))\n",
        "  return pipeline"
      ],
      "metadata": {
        "id": "7mtPk4g-SYOk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_feedback_proba(pipeline, sample):\n",
        "    sample_df = pd.DataFrame([sample])\n",
        "    sample_df = sample.to_frame().T\n",
        "    y_prob = pipeline.predict_proba(sample_df)\n",
        "    prob_pos = y_prob[0][1] * 100  # Probability of being positive\n",
        "    prob_neg = y_prob[0][0] * 100  # Probability of being negative\n",
        "    return prob_pos, prob_neg"
      ],
      "metadata": {
        "id": "chgGyXrFPYRW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate detailed feedback using OpenAI's GPT-4\n",
        "def generate_detailed_feedback(numerical_data, textual_feedback, prob_pos, prob_neg):\n",
        "    # Convert numerical_data to a string representation\n",
        "    numerical_data_str = str(numerical_data)\n",
        "\n",
        "    prompt = f\"Using the following numerical ratings and feedback:\\n\\nNumerical Ratings: {numerical_data_str}\\n\\nTextual Feedback: {textual_feedback}\\n\\nProbability of being positive: {prob_pos:.2f}%\\n\\nProbability of being negative: {prob_neg:.2f}%\\n\\nPlease provide a very short final feedback according to the client, i.e, either positive or negative. Not both. Give output in the form of either Positive, Mostly Positive, Negative or Mostly Negative with the probability percentage. And then Improvements or Matters to focus upon:\"\n",
        "    chat_completion = client.chat.completions.create(\n",
        "    messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"you are a helpful assistant.\"\n",
        "    },\n",
        "{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt, # Use the formatted prompt here\n",
        "    },\n",
        "    ],\n",
        "    model=\"llama3-8b-8192\" # Add the model keyword argument here\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content.strip()  # Extract the content from the response\n"
      ],
      "metadata": {
        "id": "22JEbmF3PlFG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feedback(pipeline, sample):\n",
        "  # Example usage\n",
        "  #prob_pos, prob_neg = predict_feedback_proba(pipeline, sample)\n",
        "  #print(f\"Sample:\\n{sample}\")\n",
        "  #print(f\"Probability of being positive: {prob_pos:.2f}%\")\n",
        "  #print(f\"Probability of being negative: {prob_neg:.2f}%\")\n",
        "\n",
        "  numerical_data = sample.drop('All_feedback').to_dict()\n",
        "  textual_feedback = sample['All_feedback']\n",
        "  prob_pos, prob_neg = predict_feedback_proba(pipeline, sample)\n",
        "  detailed_feedback = generate_detailed_feedback(numerical_data, textual_feedback, prob_pos, prob_neg)\n",
        "  print(detailed_feedback)"
      ],
      "metadata": {
        "id": "FuvUnEaXPqT_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_ready():\n",
        "  dataset_url = input(\"Enter the dataset URL: \")\n",
        "  df = prepare_data(dataset_url)\n",
        "  pipeline = train_test_model(df)\n",
        "  return pipeline"
      ],
      "metadata": {
        "id": "_cn-ZjUsbu2h"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feedback(pipeline):\n",
        "  feedform_url = input(\"Enter the URL where feedback data for generating analysis is stored: \")\n",
        "  data = prepare_data(feedform_url)\n",
        "  for i in range(len(data)):\n",
        "    sample = data.iloc[i]\n",
        "    print(\"Feedback: \", i+1)\n",
        "    generate_feedback(pipeline, sample)"
      ],
      "metadata": {
        "id": "SnCq-zL8aUKo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_execute():\n",
        "  pipeline = get_model_ready()\n",
        "  get_feedback(pipeline)"
      ],
      "metadata": {
        "id": "yd3cn9BTQDip"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  final_execute()"
      ],
      "metadata": {
        "id": "7XmcwX3Jjyi_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auVE5K3HlVhV",
        "outputId": "78ae8d34-1456-46a1-e3c3-f7ff3bdde228"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the dataset URL: /content/drive/MyDrive/Sayan RP files/Datasets/Client Feedback Form 1.csv\n",
            "Enter the URL where feedback data for generating analysis is stored: /content/drive/MyDrive/Sayan RP files/Datasets/Client Feedback Form 1.csv\n",
            "Feedback:  1\n",
            "Based on the provided numerical ratings and feedback, I would say that the final feedback is:\n",
            "\n",
            "Positive (53.19%)\n",
            "\n",
            "Improvements or Matters to focus upon:\n",
            "\n",
            "* Improve response time and clarity in communication.\n",
            "* Enhance understanding of business requirements by being more proactive and inquiring.\n",
            "* Increase knowledge in technology used for faster resolution.\n",
            "* Maintain high levels of courtesy, respect, and professionalism throughout interactions.\n",
            "Feedback:  2\n",
            "Based on the provided numerical ratings and feedback, I would classify the final feedback as:\n",
            "\n",
            "**Mostly Positive** (86.09%)\n",
            "\n",
            "Improvements or Matters to Focus Upon:\n",
            "\n",
            "* Providing more clear and understandable information to clients (rated 2.0)\n",
            "* Improving response time to client inquiries or concerns (rated 3.0 and 4.0)\n",
            "\n",
            "The positive aspects of the interaction include effective communication, prompt responses, good issue handling, and high levels of knowledge about the technology used. However, there is room for improvement in providing clear information and responding promptly to client concerns.\n",
            "Feedback:  3\n",
            "Based on the numerical ratings and feedback, the final feedback is:\n",
            "\n",
            "**Positive** (84.54%)\n",
            "\n",
            "Improvements or Matters to focus upon:\n",
            "\n",
            "* Employee's professionalism (1.0/5.0) could be improved.\n",
            "* Employee's understanding of business requirements (3.0/5.0) could be improved.\n",
            "* Employee's knowledge about the technology used (3.0/5.0) and Business domain (3.0/5.0) could be improved.\n",
            "* Employee's frankness could be balanced with professionalism.\n",
            "Feedback:  4\n",
            "Final Feedback: Negative\n",
            "\n",
            "Probability of being negative: 89.04%\n",
            "\n",
            "Improvements or Matters to focus upon:\n",
            "\n",
            "* Improving communication and response time from the employee\n",
            "* Enhancing understanding of business requirements\n",
            "* Increasing knowledge about technology and business domain\n",
            "* Providing clearer and more understandable information to clients\n",
            "* Maintaining professionalism and courtesy in interactions\n",
            "Feedback:  5\n",
            "Based on the numerical ratings and textual feedback, I would categorize the feedback as:\n",
            "\n",
            "**Mostly Negative** (66.37%)\n",
            "\n",
            "Final Feedback: Negative\n",
            "\n",
            "Improvements or Matters to focus upon:\n",
            "\n",
            "* Improve understanding of business requirements\n",
            "* Handle issues and concerns more effectively\n",
            "* Gain more experience and knowledge of the business domain\n",
            "* Enhance professional and courteous behavior during interactions\n",
            "Feedback:  6\n",
            "Based on the numerical ratings and text feedback, I'm glad to provide the final feedback to the client.\n",
            "\n",
            "Final Feedback: Mostly Positive (67.58%)\n",
            "\n",
            "Improvements or Matters to Focus Upon:\n",
            "\n",
            "* Improve communication clarity and understandability (Average rating of 2.0 for \"How clear and understandable was the information provided by the employee?\")\n",
            "* Enhance knowledge and experience in business domain (Average rating of 2.0 for \"How knowledgeable was the employee about the Business domain?\")\n",
            "* Improve issue resolution skills (Average rating of 2.0 for \"How effectively did the employee handle any issues or concerns you had?\")\n",
            "\n",
            "Note: The client's feedback suggests that the employee was fast, prompt, and knowledgeable about technology, which contributed to a positive experience. However, there were some areas for improvement, such as communication clarity and business domain expertise.\n",
            "Feedback:  7\n",
            "Based on the provided numerical ratings and feedback, I would classify the feedback as:\n",
            "\n",
            "Negative (96.72%)\n",
            "\n",
            "Improvements or Matters to focus upon:\n",
            "\n",
            "* Communication: The employee's communication skills need improvement, as the client felt they were not effective or prompt.\n",
            "* Responsiveness: The employee took a long time to respond to inquiries and concerns, which is concerning.\n",
            "* Technical knowledge: The employee lacked knowledge about the technology used and the business domain, which may have caused misunderstandings.\n",
            "* Problem-solving: The employee struggled to handle issues or concerns, leading to dissatisfaction.\n",
            "* Professionalism and courtesy: The employee's conduct was unprofessional and uncourteous, which is unacceptable in a service-oriented role.\n"
          ]
        }
      ]
    }
  ]
}